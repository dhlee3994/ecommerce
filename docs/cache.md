<!-- TOC -->

* [캐시란?](#캐시란)
    * [파레토의 법칙 + 데이터 지역성](#파레토의-법칙--데이터-지역성)
* [캐싱 전략](#캐싱-전략)
    * [캐시 읽기 전략](#캐시-읽기-전략)
        * [Cache-Aside (Look-Aside, Lazy Loading)](#cache-aside-look-aside-lazy-loading)
        * [Read-Through](#read-through)
    * [캐시 쓰기 전략](#캐시-쓰기-전략)
        * [Write Through](#write-through)
        * [Write Back (Write Behind)](#write-back-write-behind)
        * [Write Around](#write-around)
* [캐시 적용 보고서](#캐시-적용-보고서)
    * [개요](#개요-5)
    * [캐싱 전략](#캐싱-전략-1)
        * [테스트 - 실제 API 호출](#테스트---실제-api-호출)
        * [테스트 - 테스트 코드](#테스트---테스트-코드)
    * [결론](#결론)

<!-- TOC -->

# 캐시란?

Cache란 데이터나 값을 미리 복사해 놓는 임시 장소를 가리킨다.      
데이터에 접근하는 시간이 오래 걸리거나 값을 다시 계산하는 시간을 절약하고 싶은 경우에 사용한다.    
따라서, 캐시를 사용하면 리소스 사용량을 줄이고, 성능을 향상시킬 수 있다. 그런데 가장 대표적인 캐시인 CPU 내부 캐시를 생각해보면  
용량은 매우 적고, 가격은 매우 비싸다. "적은 용량, 높은 가격"인 캐시가 어떻게 시스템 성능 향상시킬 수 있을까?

## 파레토의 법칙 + 데이터 지역성

파레토의 법칙에 따르면 "80%의 요청이 전체 데이터의 20%에 집중"된다. 즉, 소수의 **핫 데이터**에 대한 요청이 반복적으로 발생한다.    
또한, 데이터의 시간 지역성(Temporal Locality)에 따르면 최근 사용한 데이터에 다시 접근하는 경향이 있다.    
따라서, 캐시 저장소의 용량이 적더라도 대부분의 요청에 대해 캐시가 작동할 가능성이 높다.

# 캐싱 전략

캐시를 사용하면 필연적으로 DB와의 **데이터 정합성** 문제가 발생하기 때문에 언제, 어떻게 캐시를 활용할지 결정해야 한다.  
이를 캐싱 전략이라고 하고 **읽기 전략**과 **쓰기 전략**으로 나뉜다.

## 캐시 읽기 전략

<details>
<summary>접기/펼치기</summary>

### Cache-Aside (Look-Aside, Lazy Loading)

#### 개요

요청에 대해 캐시를 조회 후 데이터가 없으면 DB에서 데이터를 가져온 후 캐시에 저장하는 방식.

#### 장점

- 구현이 단순하고 범용적으로 사용됨
- 캐시 장애 발생 시 바로 DB로 fallback할 수 있어 안정적.
- 필요한 데이터만 캐시에 저장하므로 불필요한 자원 낭비를 줄일 수 있음

#### 단점

- 캐시 미스시 DB 접근이 발생해 최초 데이터 조회시 응답 지연이 길어질 수 있음
- 캐시에 데이터가 있으면 바로 반환하므로 **데이터 정합성**문제가 발생할 수 있음
- 캐시 워밍업(Cache Warming) 작업이 별도로 필요할 수 있음

#### 언제 적용할까?

- 읽기가 많은 시스템 (e.g. 상품 목록, 사용자 프로필)
- 모든 데이터를 미리 캐싱하기에는 부담스러운 경우

### Read-Through

#### 개요

요청에 대해 캐시에서만 데이터를 조회하는 방식. Cache-Aside 방식과는 다르게 데이터 로딩을 캐시 시스템이 담당한다.

#### 장점

- 캐시에 없는 데이터를 (캐시 시스템이) 자동으로 채워줘서 데이터 정합성 관리가 쉬움
- 애플리케이션에서 캐시 로직을 관리할 필요가 없음
- 캐시 미스시 캐시 시스템이 자동으로 처리해줌

#### 단점

- 캐시 미스시 조회 지연이 발생할 수 있음
- 캐시 제공 라이브러리나 프레임워크에 의존해야 함
- 초기 설정 복잡

#### 언제 적용할까?

- 읽기가 많은 시스템 + 캐시 로직을 캐시 시스템에게 위임하고 싶은 경우

</details>

<details>
<summary>접기/펼치기</summary>

## 캐시 쓰기 전략

### Write Through

#### 개요

데이터를 캐시에 먼저 저장하고, 캐시가 DB에 반영하는 방식. DB에 쓰기 작업을 캐시 시스템이 담당한다.

#### 장점

- 캐시와 DB의 데이터 일관성
- 읽기 요청시 항상 최신 데이터를 가져올 수 있음

#### 단점

- 쓰기 성능이 낮아질 수 있음(=쓰기 지연시간이 증가할 수 있음)
- 불필요한 캐시가 적재될 가능성이 있음

#### 언제 적용할까?

- 데이터의 일관성이 중요한 경우
- 읽기 빈도가 높은 경우

### Write Back (Write Behind)

#### 개요

데이터를 캐시에 먼저 저장하고, DB에는 **비동기**적으로 갱신

#### 장점

- 쓰기시 메모리에만 저장되므로 쓰기 성능이 매우 빠름
- 대량의 쓰기 요청시 DB 부하 감소

#### 단점

- 캐시에 장애가 발생하면 데이터 유실 가능
- 데이터의 일관성을 보장하기 어렵고, 복잡한 동기화 전략이 필요함

#### 언제 적용할까?

- 쓰기 작업이 많은 경우 (e.g. 로그 데이터 저장)
- 데이터 유실이 어느정도 허용되는 경우

### Write Around

#### 개요

데이터를 캐시에 저장하지 않고, DB에 직접 저장하는 방식. 읽기 요청 발생시 캐시에 저장

#### 장점

- 불필요한 캐시가 적재되는 것을 방지
- 캐시는 읽기 작업에만 집중하므로, 캐시 구현이 단순해짐

#### 단점

- 데이터 최초 조회시 캐시 미스로 읽기 성능 저하

#### 언제 적용할까?

- 쓰기 작업이 많고, 읽기 작업이 상대적으로 적거나 특정 데이터만 자주 조회되는 경우 (e.g. 뉴스 기사)
- 중요한 정보만 캐싱하고 싶을 때

</details>

# 캐시 적용 보고서

## 개요

이커머스에서 캐시를 적용하기에 가장 적절한 API는 "인기 상품 조회 API"이다.  
인기 상품 조회 API는 최근 3일간 가장 많이 판매된 상품 5개를 조회하는 API이며, 이는 도메인 특성상 매우 빈번하게 호출될 것으로 예상된다.  
또한, "최근 3일"이라는 도메인 요구사항에 의해 캐시 만료 시간이 24시간으로 길기때문에 캐시를 적용하기 매우 적절하다.  
특히나 통계 쿼리를 통해 조회되던 것을 단순한 조회 쿼리로 변경하여 캐시 적용 시 성능 향상이 매우 클 것으로 예상된다.

## 캐싱 전략

"인기 상품 조회 API"는 쓰기 작업이 없는 100% 읽기 작업인 API이다. 따라서 캐시 쓰기 전략은 고려하지 않았다.  
아래의 이유들로 해당 API의 캐시 읽기 전략은 Cache-Aside 방식을 사용하기로 했다.

- 적은 데이터 변경 빈도: 데이터의 변경 주기가 1일로 매우 길다.
- 큰 데이터 계산 비용: 인기 상품 목록은 최근 3일간의 판매 데이터를 집계해야 하므로 계산 비용이 높다.
- 명확한 데이터 갱신 시점: 캐시 데이터의 갱신 시점이 명확하므로 개발자가 직접 갱신하는 것이 좋다.
- 캐시 스탬피드 방지: 캐시 스탬피드 방지를 위해 개발자가 직접 캐시 데이터를 컨트롤하는 것이 좋다.

또한, 캐시 스탬피드 현상을 방지하기 위해 캐시 만료시간을 실제 갱신 주기인 24시간보다 1시간 긴 25시간으로 설정했으며,  
캐시 미스시 DB 접근 시 분산 락을 통해 하나의 스레드만 DB에 접근하도록 설정했다.

### 테스트 - 실제 API 호출

테스트 데이터는 아래와 같다.

![all-data.png](/docs/cache/all-data.png)

"인기 상품 조회 API"에서 사용하는 쿼리를 직접 실행하면 소요 시간은 약 3초이다.

![query.png](/docs/cache/query.png)

캐시 미스시 3389ms가 걸렸다.

![with-real-no-cache.png](/docs/cache/with-real-no-cache.png)

캐시 히트시 7ms가 걸렸다.

![with-real-yes-cache.png](/docs/cache/with-real-yes-cache.png)

### 테스트 - 테스트 코드

테스트는 "하나의 상품을 n개 주문하는 주문을 10개 생성"해 진행했다.

![with-test-code.png](/docs/cache/with-test-code.png)

## 결론

API 응답 시간이 캐시 적용 전 3389ms에서 캐시 적용 후 7ms로 최대 484배 감소했다.
